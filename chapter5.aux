\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{aleman_high_dimensional}
\citation{cit:avez99searching}
\citation{lsh}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}B\IeC {\'u}squeda aproximada v\IeC {\'\i }a \textit  {Deep Hashing}}{53}{chapter.162}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Consideraciones Iniciales}{53}{section.163}}
\citation{DBLP:journals/jidm/OcsaS10}
\citation{ImageNet}
\citation{kLin:DH}
\citation{DBLP:journals/corr/YosinskiCBL14}
\AC@undonewlabel{acro:LSH}
\newlabel{acro:LSH}{{5.1}{54}{Consideraciones Iniciales}{section*.164}{}}
\acronymused{LSH}
\acronymused{LSH}
\acronymused{CNN}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Approximate Nearest Neighbors \& Deep Hashing}{54}{subsection.165}}
\@writefile{toc}{\contentsline {subsubsection}{Hashing para la B\IeC {\'u}squeda del Vecino m\IeC {\'a}s Cercano}{54}{subsection.165}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces  Hashing para la b\IeC {\'u}squeda del vecino m\IeC {\'a}s cercano. Comprimir un conjunto de vectores $(x_i)^{n}_{i=1}, x_i \in \mathbf  {R}^d $ }}{55}{figure.166}}
\newlabel{searchmodelcap5}{{5.1}{55}{Hashing para la búsqueda del vecino más cercano. Comprimir un conjunto de vectores $(x_i)^{n}_{i=1}, x_i \in \mathbf {R}^d $}{figure.166}{}}
\@writefile{toc}{\contentsline {subsubsection}{Supervised Hashing}{55}{figure.166}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Protocolos de evaluaci\IeC {\'o}n de recuperaci\IeC {\'o}n}{55}{subsection.168}}
\citation{sablayrolles2016should}
\citation{wang13}
\citation{Bettaiah14}
\citation{wekwek}
\citation{wekwek}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces  Supervised Hashing: comprime un conjunto de vectores y sus etiquetas $((x_i,y_2))^{n}_{i=1}, x_1\in \mathbb  {R}^{d}, y_1 \in \{1,...,L\} $.}}{56}{figure.167}}
\newlabel{supervisedhashingcap5}{{5.2}{56}{Supervised Hashing: comprime un conjunto de vectores y sus etiquetas $((x_i,y_2))^{n}_{i=1}, x_1\in \mathbb {R}^{d}, y_1 \in \{1,...,L\} $}{figure.167}{}}
\@writefile{toc}{\contentsline {subsubsection}{Protocolos de evaluaci\IeC {\'o}n de SH y SSH}{56}{subsection.168}}
\@writefile{toc}{\contentsline {subsubsection}{Representaci\IeC {\'o}n de datos y medidas de similitud}{56}{subsection.168}}
\newlabel{sec:methods_reduce}{{5.1.2}{56}{Representación de datos y medidas de similitud}{subsection.168}{}}
\citation{Faloutsos94}
\citation{Bettaiah14}
\citation{Faloutsos94}
\citation{Bettaiah14}
\citation{han2011data}
\citation{citeulike:fractal:encoders}
\citation{DBLP:journals/corr/SablayrollesDJU16}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Dimensi\IeC {\'o}n fractal y reducci\IeC {\'o}n de dimensionalidad}{57}{subsection.169}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Comparaci\IeC {\'o}n de representaciones de datos}{57}{subsection.170}}
\@writefile{toc}{\contentsline {subsubsection}{Dimensi\IeC {\'o}n fractal y reducci\IeC {\'o}n de dimensionalidad}{57}{subsection.170}}
\newlabel{sec:fractal-dimension}{{5.1.4}{57}{Dimensión fractal y reducción de dimensionalidad}{subsection.170}{}}
\citation{lecun-mnisthandwrittendigit-2010}
\citation{cifar10}
\citation{svhn}
\citation{DelCorso:2005:RSN:1060745.1060764}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Dimensiones Fractal para diferentes m\IeC {\'e}todos de reducci\IeC {\'o}n.}}{58}{figure.175}}
\newlabel{fig:datasetscap5}{{5.3}{58}{Dimensiones Fractal para diferentes métodos de reducción}{figure.175}{}}
\citation{sutherland1975introduction}
\citation{Gower82}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Precisi\IeC {\'o}n (P) de la clasificaci\IeC {\'o}n usando el clasificador KNN en los conjuntos de datos MNIST, CIFAR-10, SVHN y Agnews utilizando AutoEncoders y PCA como m\IeC {\'e}todos de reducci\IeC {\'o}n de dimensionalidad.}}{59}{table.176}}
\newlabel{table-result}{{5.1}{59}{Precisión (P) de la clasificación usando el clasificador KNN en los conjuntos de datos MNIST, CIFAR-10, SVHN y Agnews utilizando AutoEncoders y PCA como métodos de reducción de dimensionalidad}{table.176}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces An\IeC {\'a}lisis de precisi\IeC {\'o}n de clasificaci\IeC {\'o}n usando autoencoders para diferentes m\IeC {\'e}tricas.}}{59}{table.177}}
\newlabel{accuracy-similarities-ae}{{5.2}{59}{Análisis de precisión de clasificación usando autoencoders para diferentes métricas}{table.177}{}}
\@setckpt{chapter5}{
\setcounter{page}{61}
\setcounter{equation}{0}
\setcounter{enumi}{6}
\setcounter{enumii}{3}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{1}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{3}
\setcounter{table}{2}
\setcounter{parentequation}{0}
\setcounter{AM@survey}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{Item}{14}
\setcounter{bookmark@seq@number}{46}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{1}
\setcounter{algocf}{0}
\setcounter{ALC@line}{9}
\setcounter{ALC@rem}{0}
\setcounter{listing}{0}
\setcounter{lstnumber}{25}
\setcounter{section@level}{0}
\setcounter{lstlisting}{0}
}
